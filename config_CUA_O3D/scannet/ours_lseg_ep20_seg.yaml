DATA:
  data_root: /leonardo_work/IscrC_EEOL_0/openscene_save_files/data/scannet_3d
  data_root_2d_fused_feature: /leonardo_scratch/fast/IscrC_EEOL_0/my_reExtract_scannet_lseg
  data_root_2d_fused_feature_dinov2: /leonardo_work/IscrC_OVUD/another_lexicon_3d_feats_path/dinov2_not_aligned_sameAsOld
  feature_2d_extractor: lseg
  classes: 20
  aug: True
  voxel_size: 0.02
  input_color: False
  use_shm: False
  
DISTILL:
  arch_3d: MinkUNet18A
  ignore_label: 255
  train_gpu: [0]
  workers: 8  # data loader workers
  batch_size: 4 # 8 # 1  # batch size for training
  batch_size_val: 1  # batch size for validation during training, memory and speed tradeoff
  # base_lr: 0.0001
  # loss_type: cosine # l1 | cosine
  # loss_dinov2_type: cosine
  # loop: 5
  # epochs: 20 # 100
  # start_epoch: 0
  # power: 0.9
  # momentum: 0.9
  base_lr: 0.0001 # 0.01
  loop: 5
  epochs: 20
  start_epoch: 0
  power: 0.9
  momentum: 0.9
  weight_decay: 0.0001
  manual_seed: 1463
  print_freq: 10
  save_freq: 1
  save_path:
  resume:
  init:
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  eval_freq: 1

TEST:
  split: val  # split in [train, val]
  prompt_eng: True
  mark_no_feature_to_unknown: True
  feature_type: 'ensemble' # 'distill' | 'fusion' | 'ensemble'
  save_feature_as_numpy: False
  vis_input: False
  vis_pred: False
  vis_gt: False
  test_workers: 8
  test_gpu: [0]
  test_batch_size: 1
  test_repeats: 5
  model_path:
  save_folder:

Distributed:
  dist_url: tcp://127.0.0.1:6787
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0
