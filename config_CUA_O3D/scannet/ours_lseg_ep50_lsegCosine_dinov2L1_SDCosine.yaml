DATA:
  # data_root: /home/jinlong.li/codebase/openSet_3D/openscene_preECCV24/data/scannet_3d
  # data_root_2d_fused_feature: /mhug/mhug-dataset/jinlong_li_datasets/data_from_yoda_2d_embedding/re_my_extraction_scannet_lseg
  # data_root_2d_fused_feature_dinov2: /mhug/mhug-dataset/jinlong_li_datasets/data_from_yoda_2d_embedding/re_my_extraction_scannet_lseg
  data_root: /leonardo_work/IscrC_bal/OV3D/datas/scannet_3d
  data_root_2d_fused_feature: /leonardo_work/IscrC_bal/OV3D/datas/my_reExtract_scannet_lseg
  # data_root_2d_fused_feature_dinov2: /leonardo_work/IscrC_GMAM/lijinlong_openSet_3D_datas/lexicon_3d_feats/dinov2_not_aligned_sameAsOld
  data_root_2d_fused_feature_dinov2: /leonardo_work/IscrC_OVUD/another_lexicon_3d_feats_path/dinov2_not_aligned_sameAsOld
  data_root_2d_fused_feature_sd: /leonardo_work/IscrC_GMAM/lijinlong_openSet_3D_datas/lexicon_3d_feats/sd_not_aligned_sameAsOld
  feature_2d_extractor: lseg
  classes: 20
  aug: True
  voxel_size: 0.02
  input_color: False
  use_shm: False
  
DISTILL:
  arch_3d: MinkUNet18A
  ignore_label: 255
  train_gpu: [0]
  workers: 8  # data loader workers
  batch_size: 4 # 8 # 1  # batch size for training
  # batch_size: 1
  batch_size_val: 1  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.0001
  loss_type: cosine # l1 | cosine
  loss_dinov2_type: cosine
  loss_sd_type: cosine
  loop: 5
  epochs: 50 # 100
  start_epoch: 0
  power: 0.9
  momentum: 0.9
  manual_seed: 1463
  print_freq: 10
  save_freq: 1
  save_path:
  resume:
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  eval_freq: 1

TEST:
  split: val  # split in [train, val]
  prompt_eng: True
  mark_no_feature_to_unknown: True
  feature_type: 'ensemble' # 'distill' | 'fusion' | 'ensemble'
  save_feature_as_numpy: False
  vis_input: False
  vis_pred: False
  vis_gt: False
  test_workers: 8
  test_gpu: [0]
  test_batch_size: 1
  test_repeats: 5
  model_path:
  save_folder:

Distributed:
  dist_url: tcp://127.0.0.1:6787
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0
